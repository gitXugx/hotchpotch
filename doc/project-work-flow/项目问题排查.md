# 项目问题排查
> 根据实际情况，一般如果上线应用很长时间，之前服务都是问题定的，突然出现问题，首先排查外在问题，然后排查内在问题

一般在有经验的情况下，可以判断出是因为外在还是内在因素：

1. 例如 上海的服务没问题，但是深圳的服务有问题，像这种极有可能是平台有问题，或者DNS问题。
2. 服务本身可以访问，但是响应很慢，或者业务本身出现bug，或者有时访问是好的有时访问是由问题的，有可能是内在因素，例如服务挂了，注册中心剔除不及时导致负载均衡有问题。
   
**绝大部分因为资源不足和bug问题**

**资源分为**
1. CPU资源、磁盘IO资源、网络连接资源、内存资源
2. 由于上面资源不足导致的性能问题或bug，或者是资源使用不合理导致的性能问题或bug

## 外在问题

1. 平台是否有问题
2. 运营是否搞活动，导致用户访问量突增
3. 网络是否有波动
4. 依赖的其他系统是否发布新的东西


**平台问题：** 如果使用阿里云、腾讯云等云服务器的话，如果部分地区服务或者整个服务不可用，极可能是云平台出现问题了，这种出现问题的也不少，只能等待平台修复

**运营搞活动：** 一般运维搞活动进行报备，开发做对应的服务监控，服务降级，以防突增的流量打垮服务器，在高可用架构下，一般都会有服务降级，限流等防御措施

**网络波动：** 是否由于网络问题导致服务不可访问，可以直接通过ping服务器

**依赖的其他系统是否发布新的东西：** 很多问题可能是由其他系统引起的，发布新的东西导致当前系统突然服务出现问题，首先规范依赖的系统的发布，应该兼容之前的版本。如果是因为新系统的bug导致，只能修复bug来解决问题。 不过依赖的系统升级发布最好提前通知到其他系统，以做好完善的测试在上线


## 内在问题

通过监控系统已经发现是那台服务的机器有问题

1. 查看CPU是否资源被负载满
2. 查看磁盘IO资源是否被负载满，查看磁盘是否已满
3. 查看内存是否已满，swap是否被使用
4. 查看是否有大量网络连接，导致网络连接被耗尽

**CPU负载满：** 首先确定是否是当前业务进程导致CPU负载大，如果是当前业务导致CPU负载过高，高的情况有多种大致有以下几种
1. 业务代码出现死循环
2. 正则匹配或者高昂的计算
3. 过于频繁的GC
4. 线程开启太多，切换上下文频繁，导致CPU一直处于满负荷状态
5. JVM的JIT编译导致CPU负载

一般通过top命令，来查看最消耗CPU的进程，然后 `top -Hp PID` 查出最消耗的线程，然后通过jstact 出来栈信息，找到刚才最消耗CPU的线程在做什么操作定位其问题。`VMstat 2 10 -t` 来查看cpu上下文切换(cs)，内存(free)等信息每 两秒打印一次，打印10次。来确定CPU的负载是否由线程的上下文切换引起的。`jstat -gc 12538 5000` 进程号 间隔时间 来进行监控GC的情况


**磁盘IO资源是否被负载满：**

可以使用 `iotop` 命令来查看磁盘的读写压力，该一般出现在读写磁盘的应用向mysql、多台实例redis同时进行数据备份等

**查看网络连接**
使用 `nestat -t` 来查看多少的tcp连接和连接的状态，来判断该服务器连接资源是否被耗尽


## 服务的高可用和高性能

1. 合理使用连接池和线程池来进行优化应用对资源的使用，来提高服务的性能
2. 通过限流、服务降级、断路来保证服务接受的流量在可控的范围内，使业务具有更强的鲁棒性


